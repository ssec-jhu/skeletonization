{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train images to  \"target_folder\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "# Specify the directories\n",
    "current_folder = 'Users/vkluzner/OneDrive/NeuralMorphology/Simulations_16bit_Size3334/images/'\n",
    "target_folder = os.path.join(current_folder, '../TrainingKit/img_train_shape/')\n",
    "\n",
    "# Ensure the destination folder eyists\n",
    "os.makedirs(target_folder, eyist_ok=True)\n",
    "keyword = \"Realistic-SBR-\"\n",
    "\n",
    "# List all files in the current folder that contain the keyword\n",
    "files_with_keyword = [\n",
    "    f for f in os.listdir(current_folder)\n",
    "    if keyword in f and os.path.isfile(os.path.join(current_folder, f))\n",
    "]\n",
    "files_with_keyword = sorted(files_with_keyword)\n",
    "print(files_with_keyword)\n",
    "\n",
    "# Loop through files and organize them\n",
    "for file_name in files_with_keyword:\n",
    "    full_file_name = os.path.join(current_folder, file_name)\n",
    "    \n",
    "    # Drop keyword from the name and change the folder\n",
    "    new_full_file_name = os.path.join(target_folder, file_name.replace(keyword, \"\"))\n",
    "    \n",
    "    image = cv2.imread(full_file_name, cv2.IMREAD_UNCHANGED)  # or IMREAD_COLOR if 3 channels\n",
    "    # Put the image with sizes devidable by 16 in the training location\n",
    "    if image.shape[0] % 16 == 0 and image.shape[1] % 16 == 0: # just copy the same image to the training location\n",
    "        shutil.copy(full_file_name, new_full_file_name)\n",
    "    else:\n",
    "        pad_height = math.ceil(image.shape[0] / 16) * 16 - image.shape[0]\n",
    "        pad_width = math.ceil(image.shape[1] / 16) * 16 - image.shape[1]\n",
    "        # Pad image size to be devidable by 16\n",
    "        border_type = cv2.BORDER_REPLICATE\n",
    "        padded_image = cv2.copyMakeBorder(image, math.floor(pad_height/2), math.ceil(pad_height/2), math.floor(pad_width/2), math.ceil(pad_width/2), border_type)\n",
    "        cv2.imwrite(new_full_file_name, padded_image)\n",
    "\n",
    "    print(new_full_file_name)\n",
    "    \n",
    "print(\"Copy to img_train_shape folder complete.\")\n",
    "\n",
    "\n",
    "target_folder = os.path.join(current_folder, '../TrainingKit/img_train2/')\n",
    "# Ensure the destination folder eyists\n",
    "os.makedirs(target_folder, eyist_ok=True)\n",
    "keyword = \"Skeleton\"\n",
    "\n",
    "# List all files in the current folder that contain the keyword\n",
    "files_with_keyword = [\n",
    "    f for f in os.listdir(current_folder)\n",
    "    if keyword in f and os.path.isfile(os.path.join(current_folder, f))\n",
    "]\n",
    "files_with_keyword = sorted(files_with_keyword)\n",
    "print(files_with_keyword)\n",
    "\n",
    "# Loop through files and organize them\n",
    "for file_name in files_with_keyword:\n",
    "    full_file_name = os.path.join(current_folder, file_name)\n",
    "    # Drop keyword from the name and change the folder\n",
    "    for cntr in range(1, 6):\n",
    "        new_full_file_name = os.path.join(target_folder, file_name.replace(keyword, str(cntr)))\n",
    "        \n",
    "        image = cv2.imread(full_file_name, cv2.IMREAD_UNCHANGED)  # or IMREAD_COLOR if 3 channels\n",
    "        # Put the image with sizes devidable by 16 in the training location\n",
    "        if image.shape[0] % 16 == 0 and image.shape[1] % 16 == 0: # just copy the same image to the training location\n",
    "            shutil.copy(full_file_name, new_full_file_name)\n",
    "        else:\n",
    "            pad_height = math.ceil(image.shape[0] / 16) * 16 - image.shape[0]\n",
    "            pad_width = math.ceil(image.shape[1] / 16) * 16 - image.shape[1]\n",
    "            # Pad image size to be devidable by 16\n",
    "            border_type = cv2.BORDER_REPLICATE\n",
    "            padded_image = cv2.copyMakeBorder(image, math.floor(pad_height/2), math.ceil(pad_height/2), math.floor(pad_width/2), math.ceil(pad_width/2), border_type)\n",
    "            cv2.imwrite(new_full_file_name, padded_image)\n",
    "        \n",
    "        print(new_full_file_name)\n",
    "    \n",
    "print(\"Copy to img_train2 folder complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# Specify the directory\n",
    "folder_path = target_folder\n",
    "pickle_file = '../dataloader/annotation/dataset5.pkl'\n",
    "\n",
    "# Initialize lists for train and val files\n",
    "train_files = []\n",
    "val_files = []\n",
    "\n",
    "# Loop through files and organize them\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Define criteria for splitting, e.g., keyword or random split\n",
    "    if random.random() < 0.75:  # Example criteria\n",
    "        train_files.append(file_name)\n",
    "    else:\n",
    "        val_files.append(file_name)\n",
    "\n",
    "# Create dictionary structure\n",
    "data = {'train': train_files, 'val': val_files}\n",
    "\n",
    "# Save to a .pkl file\n",
    "with open(pickle_file, 'wb') as pkl_file:\n",
    "    pickle.dump(data, pkl_file)\n",
    "\n",
    "print(\"Data saved to dataloader/annotation/dataset5.pkl\")\n",
    "\n",
    "with open(pickle_file, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Inspect the structure\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train images to  \"target_folder\" while tiling them by TxT\n",
    "\n",
    "import os\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create tiling coordinates\n",
    "T = 512\n",
    "Im_x = 3334\n",
    "Im_y = 3334\n",
    "\n",
    "n_x = math.ceil(Im_x / T)\n",
    "X_coord = np.zeros(n_x, dtype=int)\n",
    "gap_x = math.floor((T * n_x - Im_x) / (n_x - 1))\n",
    "gap_x_plus_one__amount = T * n_x - Im_x - gap_x * (n_x - 1)\n",
    "for i in range(1, n_x):\n",
    "    if i <= gap_x_plus_one__amount:\n",
    "        X_coord[i] = int(X_coord[i-1] + T - (gap_x + 1))\n",
    "    else:\n",
    "        X_coord[i] = int(X_coord[i-1] + T - gap_x)\n",
    "    \n",
    "n_y = math.ceil(Im_y / T)\n",
    "Y_coord = np.zeros(n_y, dtype=int)\n",
    "gap_y = math.floor((T * n_y - Im_y) / (n_y - 1))\n",
    "gap_y_plus_one__amount = T * n_y - Im_y - gap_y * (n_y - 1)\n",
    "for i in range(1, n_y):\n",
    "    if i <= gap_y_plus_one__amount:\n",
    "        Y_coord[i] = int(Y_coord[i-1] + T - (gap_y + 1))\n",
    "    else:\n",
    "        Y_coord[i] = int(Y_coord[i-1] + T - gap_y)\n",
    "\n",
    "\n",
    "# Specify the directories\n",
    "current_folder = '/home/idies/workspace/ssec_neural_morphology/Simulations_16bit_Size3334/images/'\n",
    "#current_folder = 'Users/vkluzner//OneDrive/NeuralMorphology/Simulations_16bit_Size3334/images/'\n",
    "target_folder = os.path.join(current_folder, '../TrainingKit/img_train_shape/')\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "keyword = \"Realistic-SBR-\"\n",
    "\n",
    "# List all files in the current folder that contain the keyword\n",
    "files_with_keyword = [\n",
    "    f for f in os.listdir(current_folder)\n",
    "    if keyword in f and os.path.isfile(os.path.join(current_folder, f))\n",
    "]\n",
    "files_with_keyword = sorted(files_with_keyword)\n",
    "print(files_with_keyword)\n",
    "\n",
    "# Loop through files and create tiles\n",
    "for file_name in files_with_keyword:\n",
    "    full_file_name = os.path.join(current_folder, file_name)\n",
    "    \n",
    "    # Drop keyword from the name and change the folder\n",
    "    new_full_file_name = os.path.join(target_folder, file_name.replace(keyword, \"\"))\n",
    "    image = cv2.imread(full_file_name, cv2.IMREAD_UNCHANGED)  # or IMREAD_COLOR if 3 channels\n",
    "    for i in range(n_y):\n",
    "        for j in range(n_x):\n",
    "            new_full_file_name_tile = new_full_file_name.replace(\".pgm\", \"_tile_\" + str(i) + \"_\" + str(j) + \".pgm\")\n",
    "            tile = image[Y_coord[i]:(Y_coord[i] + T), X_coord[j]:(X_coord[j] + T)] # Crop the ROI\n",
    "            cv2.imwrite(new_full_file_name_tile, tile)\n",
    "            print(new_full_file_name_tile)\n",
    "    \n",
    "print(\"Copy to img_train_shape folder complete.\")\n",
    "\n",
    "\n",
    "target_folder = os.path.join(current_folder, '../TrainingKit/img_train2/')\n",
    "# Ensure the destination folder exists\n",
    "os.makedirs(target_folder, exist_ok=True)\n",
    "keyword = \"Skeleton\"\n",
    "\n",
    "# List all files in the current folder that contain the keyword\n",
    "files_with_keyword = [\n",
    "    f for f in os.listdir(current_folder)\n",
    "    if keyword in f and os.path.isfile(os.path.join(current_folder, f))\n",
    "]\n",
    "files_with_keyword = sorted(files_with_keyword)\n",
    "print(files_with_keyword)\n",
    "\n",
    "# Loop through files and create tiles\n",
    "for file_name in files_with_keyword:\n",
    "    full_file_name = os.path.join(current_folder, file_name)\n",
    "    \n",
    "    # Change keyword by the number and change the folder\n",
    "    for cntr in range(1, 6):\n",
    "        new_full_file_name = os.path.join(target_folder, file_name.replace(keyword, str(cntr)))\n",
    "        image = cv2.imread(full_file_name, cv2.IMREAD_UNCHANGED)  # or IMREAD_COLOR if 3 channels\n",
    "        for i in range(n_y):\n",
    "            for j in range(n_x):\n",
    "                new_full_file_name_tile = new_full_file_name.replace(\".pgm\", \"_tile_\" + str(i) + \"_\" + str(j) + \".pgm\")\n",
    "                tile = image[Y_coord[i]:(Y_coord[i] + T), X_coord[j]:(X_coord[j] + T)] # Crop the ROI\n",
    "                cv2.imwrite(new_full_file_name_tile, tile)\n",
    "                print(new_full_file_name_tile)\n",
    "    \n",
    "print(\"Copy to img_train2 folder complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "pickle_file = '../dataloader/annotation/dataset5.pkl'\n",
    "with open(pickle_file, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Extract train and val files\n",
    "train_files = data['train']\n",
    "val_files = data['val']\n",
    "   \n",
    "# Initialize lists for train and val files\n",
    "new_train_files = []\n",
    "new_val_files = []\n",
    "\n",
    "# Loop through files and organize them\n",
    "n_x = 7\n",
    "n_y = n_x\n",
    "for file_name in train_files:\n",
    "    for i in range(n_y):\n",
    "        for j in range(n_x):\n",
    "            new_train_files.append(file_name.replace(\".pgm\", \"_tile_\" + str(i) + \"_\" + str(j) + \".pgm\"))\n",
    "            num_selected = int(0.08 * len(new_train_files))  # Calculate 8% of the total files\n",
    "            selected_train_files = random.sample(new_train_files, num_selected)  # Randomly select 8%\n",
    "            \n",
    "for file_name in val_files:\n",
    "    for i in range(n_y):\n",
    "        for j in range(n_x):\n",
    "            new_val_files.append(file_name.replace(\".pgm\", \"_tile_\" + str(i) + \"_\" + str(j) + \".pgm\"))\n",
    "            new_val_files.sort()\n",
    "            \n",
    "# Create dictionary structure\n",
    "new_data = {'train': selected_train_files, 'val': new_val_files}\n",
    "\n",
    "# Save to a .pkl file\n",
    "new_pickle_file = '../dataloader/annotation/dataset6.pkl'\n",
    "with open(new_pickle_file, 'wb') as pkl_file:\n",
    "    pickle.dump(new_data, pkl_file)\n",
    "\n",
    "print(\"Data saved to dataloader/annotation/dataset6.pkl\")\n",
    "\n",
    "with open(new_pickle_file, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Inspect the structure\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pickle file for test purposes\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Specify the directory\n",
    "pickle_file = '../dataloader/annotation/test.pkl'\n",
    "\n",
    "# Initialize lists for train and val files\n",
    "train_files = ['1-Sample-1-time-36.00.pgm']\n",
    "val_files = ['1-Sample-2-time-36.00.pgm']\n",
    "\n",
    "# Create dictionary structure\n",
    "data = {'train': train_files, 'val': val_files}\n",
    "\n",
    "# Save to a .pkl file\n",
    "with open(pickle_file, 'wb') as pkl_file:\n",
    "    pickle.dump(data, pkl_file)\n",
    "\n",
    "print(\"Data saved to \", pickle_file)\n",
    "\n",
    "with open(pickle_file, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Inspect the structure\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../dataloader/annotation/dataset6.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "values = data.get('train') + data.get('val')\n",
    "#values.sort()\n",
    "print(sorted(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "# Specify the directory\n",
    "pickle_file = '../dataloader/annotation/dataset7.pkl'\n",
    "\n",
    "filenames = []\n",
    "for sbr in range(1, 6):\n",
    "    for cntr in range(1, 101):\n",
    "        file_name = str(sbr) + \"-Sample-\" + str(cntr) + \"-time-100.00_tile_\"\n",
    "        filenames.append(file_name)\n",
    "        \n",
    "# Initialize lists for train and val files\n",
    "train_files = []\n",
    "val_files = []\n",
    "\n",
    "# Loop through files and organize them\n",
    "for file_name in filenames:\n",
    "    # Define criteria for splitting, e.g., keyword or random split\n",
    "    if random.random() < 0.75:  # Example criteria\n",
    "        for i in range(7): #(1, 6): #(7):\n",
    "            for j in range(7): #(1, 6): #(7):\n",
    "                train_files.append(file_name + str(i) + \"_\" + str(j) + \".pgm\")\n",
    "    else:\n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "                val_files.append(file_name + str(i) + \"_\" + str(j) + \".pgm\")\n",
    "\n",
    "# Create dictionary structure\n",
    "data = {'train': train_files, 'val': val_files}\n",
    "\n",
    "# Save to a .pkl file\n",
    "with open(pickle_file, 'wb') as pkl_file:\n",
    "    pickle.dump(data, pkl_file)\n",
    "\n",
    "print(\"Data saved to dataset pkl file\")\n",
    "\n",
    "with open(pickle_file, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Inspect the structure\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skelneton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
