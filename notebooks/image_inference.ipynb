{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze connected components\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "folder_path = '/Users/vkluzner/OneDrive/NeuralMorphology/Simulations_16bit_Size1024/output/ex7/evaluation/'\n",
    "file_list = glob.glob(os.path.join(folder_path, '*_pred_bin.tif'))\n",
    "print(\"Files with '_pred_bin.tif':\")\n",
    "for file in file_list:\n",
    "    image = cv2.imread(os.path.join(folder_path, file), cv2.IMREAD_UNCHANGED)\n",
    "    _, binary_image = cv2.threshold(image, 127, 1, cv2.THRESH_BINARY)\n",
    "    #num_labels, labeled_image = cv2.connectedComponents(binary_image)\n",
    "    #num_cc = num_labels - 1 # Subtract 1 to exclude the background component\n",
    "    num_labels, labeled_image, stats, centroids = cv2.connectedComponentsWithStats(binary_image, connectivity=8)\n",
    "    num_connected_components = num_labels - 1\n",
    "    num_cc = num_labels - 1 # Subtract 1 to exclude the background component\n",
    "    if num_cc > 1:\n",
    "            print(f'Number of connected components for {file} is: {num_cc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer image through tiling process\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def get_tif_images(folder):\n",
    "    tif_files = []\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".tif\"):\n",
    "                tif_files.append(os.path.join(root, file))\n",
    "    return tif_files\n",
    "\n",
    "def extend_image(orig_image, target_size):\n",
    "\n",
    "    height, width = orig_image.shape\n",
    "    \n",
    "    extended_height, extended_width = height, width\n",
    "    start_y_coord, start_x_coord = 0, 0\n",
    "    \n",
    "    if height < target_size:\n",
    "        extended_height = target_size\n",
    "        start_y_coord = (extended_height - height) // 2\n",
    "    if width < target_size:\n",
    "        extended_width = target_size\n",
    "        start_x_coord = (extended_width - width) // 2\n",
    "    extended_image = np.zeros((extended_height, extended_width), dtype=orig_image.dtype)\n",
    "    \n",
    "    # Implement Gaussian Mixture for Background Analysis:\n",
    "    pixels = orig_image.flatten().reshape(-1, 1)  # Reshape to (n_samples, 1)\n",
    "    gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "    gmm.fit(pixels)\n",
    "    means = gmm.means_.flatten()\n",
    "    variances = gmm.covariances_.flatten()\n",
    "    background_label = np.argmin(means)\n",
    "\n",
    "    # Step 3: Generate Gaussian-distributed pixel values\n",
    "    extended_image = np.random.normal(loc=means[background_label], scale=np.sqrt(variances[background_label]), size=(extended_height, extended_width))\n",
    "    extended_image[start_y_coord : start_y_coord+height, start_x_coord : start_x_coord + width] = orig_image\n",
    "    \n",
    "    return extended_image, start_y_coord, start_x_coord\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "current_path = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_path)\n",
    "# Get the parent directory\n",
    "parent_path = os.path.dirname(current_path)\n",
    "print(\"Parent Directory:\", parent_path)\n",
    "\n",
    "#sys.path.append(current_path)\n",
    "sys.path.append(parent_path)\n",
    "\n",
    "# Print the updated sys.path\n",
    "print(\"Updated sys.path:\")\n",
    "for p in sys.path:\n",
    "    print(p)\n",
    "\n",
    "# Find available GPU\n",
    "if torch.backends.mps.is_available(): # Check if PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "    print(\"MPS is available!\")\n",
    "    if torch.backends.mps.is_built():\n",
    "        print(\"MPS (Metal Performance Shader) is built in!\")    \n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available(): # Check if PyTorch has access to CUDA (Win or Linux's GPU architecture)\n",
    "    print(\"CUDA is available!\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print(\"Only CPU is available!\")\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#check out kernel\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "output_path = \"/Users/vkluzner/OneDrive/NeuralMorphology/Simulations_16bit_Size3334/output/ex7/\"\n",
    "\n",
    "from model.unet_att import UnetAttention\n",
    "model = UnetAttention()\n",
    "model = model.to(device)\n",
    "ckpt = torch.load(output_path + \"ckpt.pth\", weights_only=False, map_location=device)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Get the list of real images\n",
    "folder_path = \"/Users/vkluzner/OneDrive/NeuralMorphology/CIV_Developmental_Images/\"\n",
    "tif_images = sorted(get_tif_images(folder_path))\n",
    "\n",
    "#tif_images = ['/Users/vkluzner/OneDrive/NeuralMorphology/CIV_Developmental_Images/24hr/Processed/24hrWt1_40x_20gfp_500ms_495z_frmbottomA3A4A5-MaxIP-A3.tif',\n",
    "#              '/Users/vkluzner/OneDrive/NeuralMorphology/CIV_Developmental_Images/24hr/Processed/Oriented/24hrWt2_40x_20gfp_500ms_482z_frmlefttopA3A4A5001-MaxIP-A4-Ori.tif']\n",
    "\n",
    "# Infer the image through tiling\n",
    "T = 512 # Tile size\n",
    "threshold = 0.69\n",
    "\n",
    "for current_file in tif_images:\n",
    "    print(\"Infering image: \", current_file)\n",
    "    orig_image = cv2.imread(current_file, cv2.IMREAD_UNCHANGED)  # or IMREAD_COLOR if 3 channels\n",
    "    orig_image = cv2.convertScaleAbs(orig_image, alpha=255.0 / orig_image.max()) / 255.\n",
    "    height, width = orig_image.shape\n",
    "\n",
    "    if height < T or width < T: # Image is too small to be tiled - extend it\n",
    "        image, start_y_coord, start_x_coord = extend_image(orig_image, T)\n",
    "    else: # Image is large enough to be tiled - no need to extend\n",
    "        image = orig_image.copy()\n",
    "    Im_y, Im_x = image.shape\n",
    "    \n",
    "    # Create tiling coordinates\n",
    "    n_x = math.ceil(Im_x / T)\n",
    "    X_coord = np.zeros(n_x, dtype=int)\n",
    "    if n_x == 1:\n",
    "        gap_x = 0\n",
    "    else:\n",
    "        gap_x = math.floor((T * n_x - Im_x) / (n_x - 1))\n",
    "    gap_x_plus_one__amount = T * n_x - Im_x - gap_x * (n_x - 1)\n",
    "    for i in range(1, n_x):\n",
    "        if i <= gap_x_plus_one__amount:\n",
    "            X_coord[i] = int(X_coord[i-1] + T - (gap_x + 1))\n",
    "        else:\n",
    "            X_coord[i] = int(X_coord[i-1] + T - gap_x)\n",
    "\n",
    "    n_y = math.ceil(Im_y / T)\n",
    "    Y_coord = np.zeros(n_y, dtype=int)\n",
    "    if n_y == 1:\n",
    "        gap_y = 0\n",
    "    else:\n",
    "        gap_y = math.floor((T * n_y - Im_y) / (n_y - 1))\n",
    "    gap_y_plus_one__amount = T * n_y - Im_y - gap_y * (n_y - 1)\n",
    "    for i in range(1, n_y):\n",
    "        if i <= gap_y_plus_one__amount:\n",
    "            Y_coord[i] = int(Y_coord[i-1] + T - (gap_y + 1))\n",
    "        else:\n",
    "            Y_coord[i] = int(Y_coord[i-1] + T - gap_y)\n",
    "\n",
    "    pred_array = np.zeros((n_x * n_y, Im_y, Im_x), dtype=np.float32)\n",
    "    for i in range(n_y):\n",
    "        for j in range(n_x):\n",
    "            tile = image[Y_coord[i]:(Y_coord[i] + T), X_coord[j]:(X_coord[j] + T)] # Crop the ROI\n",
    "            # Start the infering process\n",
    "            tile_flip_0 = cv2.flip(tile, 0)\n",
    "            tile_flip_1 = cv2.flip(tile, 1)\n",
    "            tile_flip__1 = cv2.flip(tile, -1)\n",
    "            tile_stack = np.stack([tile, tile_flip_0, tile_flip_1, tile_flip__1])\n",
    "            tile_torch = torch.tensor(tile_stack).unsqueeze(1).to(torch.float32).to(device)\n",
    "            with torch.no_grad():\n",
    "                pred, _, _, _ = model(tile_torch)\n",
    "                pred = torch.sigmoid(pred)\n",
    "                pred_ori, pred_flip_0, pred_flip_1, pred_flip__1 = pred\n",
    "            pred_ori = pred_ori.cpu().numpy()\n",
    "            pred_flip_0 = cv2.flip(pred_flip_0.cpu().numpy(), 0)\n",
    "            pred_flip_1 = cv2.flip(pred_flip_1.cpu().numpy(), 1)\n",
    "            pred_flip__1 = cv2.flip(pred_flip__1.cpu().numpy(), -1)\n",
    "            tile_pred = np.mean([pred_ori, pred_flip_0, pred_flip_1, pred_flip__1], axis=0)\n",
    "            pred_array[i * n_x + j, Y_coord[i]:(Y_coord[i] + T), X_coord[j]:(X_coord[j] + T)] = tile_pred\n",
    "\n",
    "    # Averaging the result and getting \"soft\" prediction\n",
    "    non_zero_mask = pred_array != 0  # Shape (n_x * n_y, img_height, img_width)\n",
    "    non_zero_count = np.sum(non_zero_mask, axis=0)  # Shape (img_height, img_width)\n",
    "    non_zero_count[non_zero_count == 0] = 1  # Prevent division by zero\n",
    "    #non_zero_sum = np.sum(pred_array * non_zero_mask, axis=0)  # Shape (img_height, img_width)\n",
    "    #pred_image = non_zero_sum / non_zero_count  # Shape (img_height, img_width)\n",
    "    pred_image = np.max(pred_array * non_zero_mask, axis=0)\n",
    "    \n",
    "    if height < T or width < T: # Cut original size of image from extended image\n",
    "        pred_image = pred_image[start_y_coord : start_y_coord+height, start_x_coord : start_x_coord+width]\n",
    "        \n",
    "    # Getting \"hard\" prediction\n",
    "    pred_bin_image = pred_image.copy()\n",
    "    pred_bin_image[pred_bin_image >= threshold] = 1\n",
    "    pred_bin_image[pred_bin_image < threshold] = 0\n",
    "    \n",
    "    # Save original file to the output path\n",
    "    #current_file = os.path.join(output_path + 'real_mean', os.path.basename(current_file))\n",
    "    current_file = os.path.join(output_path + 'real_max', os.path.basename(current_file))\n",
    "    orig_image = (orig_image * 255).astype(np.uint8)\n",
    "    cv2.imwrite(current_file, orig_image)\n",
    "\n",
    "    # Save \"soft\" prediction\n",
    "    soft_prediction_file = current_file.replace(\".tif\", \"_pred.tif\")\n",
    "    pred_image = (pred_image * 255).astype(np.uint8)\n",
    "    cv2.imwrite(soft_prediction_file, pred_image)\n",
    "    \n",
    "    # Save \"hard\" (binary) prediction\n",
    "    current_hard_prediction = current_file.replace(\".tif\", \"_bin.tif\")\n",
    "    pred_bin_image = (pred_bin_image * 255).astype(np.uint8)\n",
    "    cv2.imwrite(current_hard_prediction, pred_bin_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skelneton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
