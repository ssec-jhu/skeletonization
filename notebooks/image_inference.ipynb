{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Trained U-Net Model\n",
    "# •\tMake sure your model is saved and accessible. For PyTorch load it with torch.load(), and for TensorFlow/Keras use keras.models.load_model()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# Get the current working directory\n",
    "current_path = os.getcwd()\n",
    "print(\"Current Working Directory:\", current_path)\n",
    "# Get the parent directory\n",
    "parent_path = os.path.dirname(current_path)\n",
    "print(\"Parent Directory:\", parent_path)\n",
    "\n",
    "#sys.path.append(current_path)\n",
    "sys.path.append(parent_path)\n",
    "\n",
    "# Print the updated sys.path\n",
    "print(\"Updated sys.path:\")\n",
    "for p in sys.path:\n",
    "    print(p)\n",
    "\n",
    "# Find available GPU\n",
    "if torch.backends.mps.is_available(): # Check if PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "    print(\"MPS is available!\")\n",
    "    if torch.backends.mps.is_built():\n",
    "        print(\"MPS (Metal Performance Shader) is built in!\")    \n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available(): # Check if PyTorch has access to CUDA (Win or Linux's GPU architecture)\n",
    "    print(\"CUDA is available!\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print(\"Only CPU is available!\")\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#check out kernel\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "\n",
    "from model.unet_att import UnetAttention\n",
    "model = UnetAttention()\n",
    "model = model.to(device)\n",
    "ckpt = torch.load(\"../../../../OneDrive/Neural Morphology/Simulations/Simulations_16bit_Size1024/output//ex5/ckpt.pth\", weights_only=False, map_location=device)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show differences on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load image\n",
    "image_16bit = cv2.imread(\"../../../../OneDrive/Neural Morphology/CIV_Developmental_Images/24Hr/Processed/Oriented/24hrWt2_40x_20gfp_500ms_482z_frmlefttopA3A4A5001-MaxIP-A4-Ori.tif\", cv2.IMREAD_UNCHANGED)  # or IMREAD_COLOR if 3 channels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Input Image\n",
    "#\t•\tEnsure the image has the same dimensions, channels, and scaling as used during training. U-Net models usually work with 2D images with dimensions like 256x256 or 512x512 pixels.\n",
    "#\t•\tNormalize or scale the pixel values if needed (e.g., dividing by 255 for images in the 0-255 range)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load image\n",
    "image_16bit = cv2.imread(\"../../../../OneDrive/Neural Morphology/CIV_Developmental_Images/24Hr/Processed/Oriented/24hrWt2_40x_20gfp_500ms_482z_frmlefttopA3A4A5001-MaxIP-A4-Ori.tif\", cv2.IMREAD_UNCHANGED)  # or IMREAD_COLOR if 3 channels\n",
    "\n",
    "# Step 2: Normalize to 8-bit\n",
    "image = cv2.normalize(image_16bit, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "height, width = image.shape\n",
    "   \n",
    "# Calculate the square size of the padded image\n",
    "pwr = math.ceil(max(math.log2(height), math.log2(width)))\n",
    "side = 2 ** pwr\n",
    "\n",
    "# Calculate start coordinates for the original image\n",
    "start_height = math.floor((side - height) / 2)\n",
    "start_width = math.floor((side - width) / 2)\n",
    "\n",
    "# Implement Gaussian Mixture for Background Analysis:\n",
    "\n",
    "# Step 2: Flatten the image\n",
    "pixels = image.flatten().reshape(-1, 1)  # Reshape to (n_samples, 1)\n",
    "\n",
    "# Step 3: Fit Gaussian Mixture Model\n",
    "gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "gmm.fit(pixels)\n",
    "\n",
    "# Step 4: Analyze GMM components\n",
    "labels = gmm.predict(pixels)  # Labels for each pixel\n",
    "means = gmm.means_.flatten()\n",
    "variances = gmm.covariances_.flatten()\n",
    "\n",
    "# Identify background component (typically the one with the lowest mean intensity)\n",
    "background_label = np.argmin(means)\n",
    "print(\"Background Label:\", background_label)\n",
    "print(\"Background Mean Intensity:\", means[background_label])\n",
    "\n",
    "# Step 5: Reshape the labels to the original image shape\n",
    "segmented_image = labels.reshape(image.shape)\n",
    "\n",
    "# Visualize the segmentation\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Segmented Background\")\n",
    "plt.imshow(segmented_image == background_label, cmap='gray')  # Highlight background\n",
    "plt.show()\n",
    "\n",
    "# Create a new array with padding, initialized with background as Gaussian variable\n",
    "# padded_image = np.zeros((side, side), dtype=image.dtype)\n",
    "# padded_image[0:side, 0:start_width] = padding_gray_level\n",
    "# padded_image[0:side, start_width+width:side] = padding_gray_level\n",
    "# padded_image[0:start_height, start_width:start_width+width] = padding_gray_level\n",
    "# padded_image[start_height+height:side, start_width:start_width+width] = padding_gray_level\n",
    "\n",
    "# Step 3: Generate Gaussian-distributed pixel values\n",
    "# Use np.random.normal to generate values for each pixel in the image\n",
    "padded_image = np.random.normal(loc=means[background_label], scale=np.sqrt(variances[background_label]), size=(side, side))\n",
    "\n",
    "# Step 4: Clip the values to the valid pixel range [0, 255] for an 8-bit grayscale image\n",
    "padded_image = np.clip(padded_image, 0, 255)\n",
    "\n",
    "# Step 5: Convert to integer values (uint8)\n",
    "padded_image = padded_image.astype(np.uint8)\n",
    "\n",
    "padded_image[start_height:start_height+height, start_width:start_width+width] = image\n",
    "cv2.imwrite(\"orig.png\", padded_image)\n",
    "\n",
    "padded_image = padded_image / 255.\n",
    "image_flip_0 = cv2.flip(padded_image, 0)\n",
    "image_flip_1 = cv2.flip(padded_image, 1)\n",
    "image_flip__1 = cv2.flip(padded_image, -1)\n",
    "image = np.stack([padded_image, image_flip_0, image_flip_1, image_flip__1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(\"../dataset/test/Realistic-SBR-1-Sample-1-time-36.00.pgm\", cv2.IMREAD_UNCHANGED)  # or IMREAD_COLOR if 3 channels\n",
    "height, width = image.shape\n",
    "# Create a new array with padding, initialized to black (0)\n",
    "template_image = np.zeros((height+24, width+24), dtype=image.dtype)\n",
    "template_image[0:12, 12:12+width] = image[0:12, 0:width]\n",
    "template_image[height+12:height+24, 12:12+width] = image[height-12:height, 0:width]\n",
    "template_image[12:12+height, 0:12] = image[0:height, 0:12]\n",
    "template_image[12:12+height, width+12:width+24] = image[0:height, width-12:width]\n",
    "template_image[0:12, 0:12] = image[height-12:height, width-12:width]\n",
    "template_image[0:12, width+12:width+24] = image[height-12:height, 0:12]\n",
    "template_image[height+12:height+24, 0:12] = image[0:12, width-12:width]\n",
    "template_image[height+12:height+24, width+12:width+24] = image[0:12, 0:12]\n",
    "padded_image = template_image\n",
    "padded_image[12:12+height, 12:12+width] = image\n",
    "cv2.imwrite(\"orig.png\", padded_image)\n",
    "\n",
    "padded_image = padded_image / 255.\n",
    "image_flip_0 = cv2.flip(padded_image, 0)\n",
    "image_flip_1 = cv2.flip(padded_image, 1)\n",
    "image_flip__1 = cv2.flip(padded_image, -1)\n",
    "image = np.stack([padded_image, image_flip_0, image_flip_1, image_flip__1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Inference\n",
    "#\t•\tPass the prepared image through the U-Net model to obtain the predicted segmentation mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch example\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    input_tensor = torch.tensor(image).unsqueeze(1).to(torch.float32).to('mps')\n",
    "    pred, _, _, _ = model(input_tensor)\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred_ori, pred_flip_0, pred_flip_1, pred_flip__1 = pred\n",
    "    pred_ori = pred_ori.cpu().numpy()\n",
    "    pred_flip_0 = cv2.flip(pred_flip_0.cpu().numpy(), 0)\n",
    "    pred_flip_1 = cv2.flip(pred_flip_1.cpu().numpy(), 1)\n",
    "    pred_flip__1 = cv2.flip(pred_flip__1.cpu().numpy(), -1)\n",
    "    pred = np.mean([pred_ori, pred_flip_0, pred_flip_1, pred_flip__1], axis=0)\n",
    "    pred = pred[start_height:start_height+height, start_width:start_width+width]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-process the Output\n",
    "#\t•\tU-Net models often output probabilities (values between 0 and 1), so you may want to apply a threshold to convert it to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.79\n",
    "binary_mask = (pred > threshold).astype(np.uint8) * 255  # Convert to 0 and 255 for binary mask\n",
    "# Save the mask\n",
    "cv2.imwrite(\"predicted_mask2.png\", binary_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display or Save the Inference Result\n",
    "#\t•\tYou can save or display the binary mask as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Output Window', binary_mask)\n",
    "# Wait for a key press indefinitely or for a specific amount of time\n",
    "cv2.waitKey(0)  # Waits indefinitely; use cv2.waitKey(1000) to wait 1 second\n",
    "# Destroy all OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skelneton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
